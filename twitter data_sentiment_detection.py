# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15TMWoChtwQmVy3s4_dMBXnfMo6yEmdO1
"""

import spacy
import pandas as pd
!pip3 install snscrape
from spacy import displacy
import snscrape.modules.twitter as sntwitter
scrapper=sntwitter.TwitterSearchScraper("#ShahidAfridi")
tweets=[]
for i,tweet in enumerate(scrapper.get_items()):
 data=[
    tweet.user.username,
    tweet.content    
 ]
 tweets.append(data)
 if i>50:
   break
tweet_df=pd.DataFrame(tweets,columns=["username","content"])
tweet_df

import nltk
nltk.download('vader_lexicon')
from nltk.sentiment import SentimentIntensityAnalyzer
from tqdm.notebook import tqdm

import re
import nltk
!pip install emoji
import emoji
from nltk.corpus import stopwords
nltk.download('stopwords')
import string
exclude = string.punctuation
# !pip

def remove_emoji(text):
    emoji_pattern = re.compile("["
                           u"\U0001F600-\U0001F64F"  # emoticons
                           u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                           u"\U0001F680-\U0001F6FF"  # transport & map symbols
                           u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                           u"\U00002702-\U000027B0"
                           u"\U000024C2-\U0001F251"
                           "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r'', text)

def remove_stopwords(text):
    new_text = []
    
    for word in text.split():
        if word in stopwords.words('english'):
            new_text.append('')
        else:
            new_text.append(word)
    x = new_text[:]
    new_text.clear()
    return " ".join(x)
def remove_url(text):
    pattern = re.compile(r'https?://\S+|www\.\S+')
    return pattern.sub(r'', text) 
def remove_punc1(text):
    return text.translate(str.maketrans('', '', exclude))          
newtext=[]
for i in tweet_df["content"]: 
 text=remove_url(i)
 text=remove_stopwords(text)
 text=remove_punc1(text)
 text=emoji.demojize(text)
 text = re.sub("@[A-Za-z0-9_]+","", text)
 text = re.sub("#[A-Za-z0-9_]+","", text)
 newtext.append(text)
tweets_df=pd.DataFrame(newtext,columns=["content"])

# remove_url(tweet_df["content"])
sia = SentimentIntensityAnalyzer()
for i in tweets_df["content"]:
    print(i)
    print(sia.polarity_scores(i))
